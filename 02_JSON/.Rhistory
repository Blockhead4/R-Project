writer <- c(writer, str_sub(tmp, 1, idx[1]-1))
tmp <- trim(str_sub(tmp, idx[1], -1))
idx <- str_locate(tmp, "\r")
time <- c(time, str_sub(tmp, 1, idx[1]-1))
#print(time)
}
result <- data.frame(score=score, review=review, writer=writer, time=time)
reviews <- rbind.data.frame(reviews, result)
review
result
reviews <- rbind(reviews, result)
reviews
reviews <- c()
for(i in 1:length(pages)) {
url_all <- paste0(ifr_base_url, pages[i])
html <- read_html(url_all)
html %>%
html_node('div.score_result') %>%
html_nodes('li') -> lis
score <- c()
writer <- c()
review <- c()
time <- c()
for (li in lis) {
score <- c(score, html_node(li, '.star_score') %>% html_text('em') %>% trim())
li %>%
html_node('.score_reple') %>%
html_text('p') %>%
trim() -> tmp
idx <- str_locate(tmp, "\r")
review <- c(review, str_sub(tmp, 1, idx[1]-1))
tmp <- trim(str_sub(tmp, idx[1], -1))
idx <- str_locate(tmp, "\r")
writer <- c(writer, str_sub(tmp, 1, idx[1]-1))
tmp <- trim(str_sub(tmp, idx[1], -1))
idx <- str_locate(tmp, "\r")
time <- c(time, str_sub(tmp, 1, idx[1]-1))
#print(time)
}
result <- data.frame(score=score, review=review, writer=writer, time=time)
reviews <- rbind.data.frame(reviews, result)
}
reviews
url <- 'https://front.wemakeprice.com/deal/600089247?source=dealsearch&search_keyword=%EA%B7%B8%EB%9E%A8&_service=5&no&extservice=ad'
html <- read_html
html <- read_html(url)
html
a <- html_node(html, 'div.review_area')
a
a <- html_nodes(html, 'div.review_area')
a
a <- html_nodes(html, '.tab_conts')
a
a <- html_node(html, '.tab_conts')
a
a <- html_nodes(html, '.review_area')
a
a <- html_node(html, '.review_area')
a <- html_node(html, '.tab_conts')
a <- html_node(html, '.review_area')
a
a <- html_node(html, '.desc_cont')
a
a <- html_node(html, '.tab_conts')
a <- html_node(html, '.desc_cont')
a
a <- html_nodes(html, '.review_area')
a
# NAVER 영화 ('스파이더맨 : 파프롬 홈') 일반인 리뷰 크롤링
ifr_base_url <- 'https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=173123&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false&page='
pages <- c(1:242)
reviews <- c()
for(i in 1:length(pages)) {
url_all <- paste0(ifr_base_url, pages[i])
html <- read_html(url_all)
html %>%
html_node('div.score_result') %>%
html_nodes('li') -> lis
score <- c()
writer <- c()
review <- c()
time <- c()
for (li in lis) {
score <- c(score, html_node(li, '.star_score') %>% html_text('em') %>% trim())
li %>%
html_node('.score_reple') %>%
html_text('p') %>%
trim() -> tmp
idx <- str_locate(tmp, "\r")
review <- c(review, str_sub(tmp, 1, idx[1]-1))
tmp <- trim(str_sub(tmp, idx[1], -1))
idx <- str_locate(tmp, "\r")
writer <- c(writer, str_sub(tmp, 1, idx[1]-1))
tmp <- trim(str_sub(tmp, idx[1], -1))
idx <- str_locate(tmp, "\r")
time <- c(time, str_sub(tmp, 1, idx[1]-1))
#print(time)
}
result <- data.frame(score=score, review=review, writer=writer, time=time)
reviews <- rbind.data.frame(reviews, result)
}
library(xlsx)
write.xlsx(reviews, "D:/workspace-Jwp/R/R-Project/01_Crowling/reviews.xlsx")
# NAVER 영화 ('스파이더맨 : 파프롬 홈') 일반인 리뷰 크롤링
library(rvest)
library(stringr)
library(dplyr)
library(xlsx)
library(rJava)
library(KoNLP)
library(wordcloud)
library(RColorBrewer)
library(ggplot2)
library(KoNLP)
# NAVER 영화 ('스파이더맨 : 파프롬 홈') 일반인 리뷰 크롤링
library(rvest)
library(stringr)
library(dplyr)
library(xlsx)
library(rJava)
library(wordcloud)
library(RColorBrewer)
library(ggplot2)
library(KoNLP)
install.packages("KoNLP")
library(KoNLP)
install.packages("KoNLP")
library(rJava)
library(KoNLP)
library(rJava)
# NAVER 영화 ('스파이더맨 : 파프롬 홈') 일반인 리뷰 크롤링
library(rvest)
library(stringr)
library(dplyr)
library(xlsx)
library(rJava)
library(wordcloud)
library(RColorBrewer)
library(ggplot2)
library(KoNLP)
# NAVER 영화 ('스파이더맨 : 파프롬 홈') 일반인 리뷰 크롤링
library(rvest)
library(stringr)
library(dplyr)
library(xlsx)
library(rJava)
library(wordcloud)
library(RColorBrewer)
library(ggplot2)
library(KoNLP)
useSejongDic()
Sys.setenv(JAVA_HOME="C:/Program Files/Java/jdk1.8.0_202")
library(rJava)
library(KoNLP)
# NAVER 영화 ('스파이더맨 : 파프롬 홈') 일반인 리뷰 크롤링
Sys.setenv(JAVA_HOME="C:/Program Files/Java/jdk1.8.0_202/")
library(rvest)
library(stringr)
library(dplyr)
library(xlsx)
library(rJava)
library(wordcloud)
library(RColorBrewer)
library(ggplot2)
library(KoNLP)
# NAVER 영화 ('스파이더맨 : 파프롬 홈') 일반인 리뷰 크롤링
Sys.setenv(JAVA_HOME="C:/Program Files/Java/jdk1.8.0_202/")
library(rvest)
library(stringr)
library(dplyr)
library(xlsx)
library(rJava)
library(wordcloud)
library(RColorBrewer)
library(ggplot2)
library(KoNLP)
library(rJava)
library(KoNLP)
# NAVER 영화 ('스파이더맨 : 파프롬 홈') 일반인 리뷰 크롤링
Sys.setenv(JAVA_HOME="C:/Program Files/Java/jre1.8.0_211")
library(rJava)
library(KoNLP)
# NAVER 영화 ('스파이더맨 : 파프롬 홈') 일반인 리뷰 크롤링
Sys.setenv(JAVA_HOME="C:/Program Files/Java/jre1.8.0_211")
library(rvest)
library(stringr)
library(dplyr)
library(xlsx)
library(rJava)
library(KoNLP)
library(wordcloud)
library(RColorBrewer)
library(ggplot2)
# NAVER 영화 ('스파이더맨 : 파프롬 홈') 일반인 리뷰 크롤링
Sys.setenv(JAVA_HOME="C:/Program Files/Java/jre1.8.0_211/")
library(rvest)
library(stringr)
library(dplyr)
library(xlsx)
library(rJava)
library(KoNLP)
library(wordcloud)
library(RColorBrewer)
library(ggplot2)
# NAVER 영화 ('스파이더맨 : 파프롬 홈') 일반인 리뷰 크롤링
Sys.setenv(JAVA_HOME="C:/Program Files/Java/jdk1.8.0_211/")
library(rvest)
library(stringr)
library(dplyr)
library(xlsx)
library(rJava)
library(KoNLP)
library(wordcloud)
library(RColorBrewer)
library(ggplot2)
useSejongDic()
install.packages("rJava")
install.packages("rJava")
library(rJava)
library(rJava)
install.packages("rJava")
# NAVER 영화 ('스파이더맨 : 파프롬 홈') 일반인 리뷰 크롤링
Sys.setenv(JAVA_HOME="C:/Program Files/Java/jdk1.8.0_211/")
library(rvest)
library(stringr)
library(dplyr)
library(xlsx)
library(rJava)
library(KoNLP)
library(wordcloud)
library(RColorBrewer)
library(ggplot2)
install.packages("rJava")
install.packages("rJava")
library(rJava)
library(rJava)
library(rJava)
# NAVER 영화 [ 스파이더맨 : 파프롬 홈 ] 일반인 리뷰 크롤링
library(rvest)
library(stringr)
library(dplyr)
library(xlsx)
library(rJava)
library(KoNLP)
library(rJava)
library(KoNLP)
# NAVER 영화 [ 스파이더맨 : 파프롬 홈 ] 일반인 리뷰 크롤링
install.packages("rJava")
install.packages("rJava")
library(rJava)
library(KoNLP)
a <- data.frame(c(1:100), c(rep('a', 'b', 50)))
a
a <- data.frame(c(1:100), c(rep('a', 'b', each=50)))
?rep
a <- data.frame(c(1:100), c(rep('a', 'b', each=T)))
rep(1, 2)
a <- data.frame(c(1:100), rep(c('a', 'b'), each=50)))
rep(c(1, 2), 3)
rep(c(1, 2), each=T)
rep(c(1, 2), 30, each=T)
rep(c(1, 2, 2), 30, each=T)
rep(c(1, 2, 2), 30)
rep(c('a','b'), each=2)
rep(c('a','b'), 2)
a <- data.frame(c(1:100), rep(c('a', 'b'), 50)))
a <- data.frame(c(1:100), rep(c('a', 'b'), 100)))
a <- data.frame(c(1:100), rep(c('a', 'b'), 100))
aa
a
a <- data.frame(c(1:100), rep(c('a', 'b'), 50)
a <- data.frame(c(1:100), rep(c('a', 'b'), 50))
?rep
a
b <- data.frame(rep(c('a', 'b'), 50), rep(c('123214', '898908'), 50))
b
?merge
# 공공데이터포털 API 이용하여 데이터 가져오기
# 지자체별 사고다발지역정보 조회 서비스
library(jsonlite)
library(openxlsx)
"http://apis.data.go.kr/B552061/frequentzoneLg"
base_url <- "http://apis.data.go.kr/B552061/frequentzoneLg/getRestFrequentzoneLg"
ServiceKey <- 'lUXI2SxeMJiWbVfle8ayTUC1QdgcmsGBIFDe%2B81qXfYDKSUHzeXPgaJBDX3IN1NognSFegD5q6ggLws8MBwarQ%3D%3D'
searchYearCd <- 2017
siDo <- 30    # 대전광역시
guGun <- 170  # 서구
numOfRows <- 10
pageNo <- 1
# http://apis.data.go.kr/B552061/frequentzoneLg/getRestFrequentzoneLg?ServiceKey=서비스키&searchYearCd=2017&siDo=26&guGun=110&numOfRows=10&pageNo=1
callback_url <- paste0(base_url, '?ServiceKey=', ServiceKey, '&searchYearCd=', searchYearCd,
'&siDo=', siDo, '&guGun=', guGun, '&numOfRows=', numOfRows,
'&pageNo=', pageNo, '&type=json')
responsData <- fromJSON(callback_url)
ServiceKey <- 'lUXI2SxeMJiWbVfle8ayTUC1QdgcmsGBIFDe%2B81qXfYDKSUHzeXPgaJBDX3IN1NognSFegD5q6ggLws8MBwarQ%3D%3D'
searchYearCd <- 2017
siDo <- 30    # 대전광역시
guGun <- 170  # 서구
numOfRows <- 10
pageNo <- 1
# http://apis.data.go.kr/B552061/frequentzoneLg/getRestFrequentzoneLg?ServiceKey=서비스키&searchYearCd=2017&siDo=26&guGun=110&numOfRows=10&pageNo=1
callback_url <- paste0(base_url, '?ServiceKey=', ServiceKey, '&searchYearCd=', searchYearCd,
'&siDo=', siDo, '&guGun=', guGun, '&numOfRows=', numOfRows,
'&pageNo=', pageNo, '&type=json')
responsData <- fromJSON(callback_url)
ServiceKey <- 'lUXI2SxeMJiWbVfle8ayTUC1QdgcmsGBIFDe%2B81qXfYDKSUHzeXPgaJBDX3IN1NognSFegD5q6ggLws8MBwarQ%3D%3D'
searchYearCd <- 2017
siDo <- 30    # 대전광역시
guGun <- 170  # 서구
numOfRows <- 10
pageNo <- 1
# http://apis.data.go.kr/B552061/frequentzoneLg/getRestFrequentzoneLg?ServiceKey=서비스키&searchYearCd=2017&siDo=26&guGun=110&numOfRows=10&pageNo=1
callback_url <- paste0(base_url, '?ServiceKey=', ServiceKey, '&searchYearCd=', searchYearCd,
'&siDo=', siDo, '&guGun=', guGun, '&numOfRows=', numOfRows,
'&pageNo=', pageNo, '&type=json')
responsData <- fromJSON(callback_url)
base_url <- "http://apis.data.go.kr/B552061/frequentzoneLg/getRestFrequentzoneLg"
ServiceKey <- 'lUXI2SxeMJiWbVfle8ayTUC1QdgcmsGBIFDe%2B81qXfYDKSUHzeXPgaJBDX3IN1NognSFegD5q6ggLws8MBwarQ%3D%3D'
searchYearCd <- 2017
siDo <- 30    # 대전광역시
guGun <- 170  # 서구
numOfRows <- 10
pageNo <- 1
# http://apis.data.go.kr/B552061/frequentzoneLg/getRestFrequentzoneLg?ServiceKey=서비스키&searchYearCd=2017&siDo=26&guGun=110&numOfRows=10&pageNo=1
callback_url <- paste0(base_url, '?ServiceKey=', ServiceKey, '&searchYearCd=', searchYearCd,
'&siDo=', siDo, '&guGun=', guGun, '&numOfRows=', numOfRows,
'&pageNo=', pageNo, '&type=json')
responsData <- fromJSON(callback_url)
# 공공데이터포털 API 이용하여 데이터 가져오기
# 지자체별 사고다발지역정보 조회 서비스
library(jsonlite)
library(openxlsx)
install.packages("jsonlite")
install.packages("jsonlite")
# 공공데이터포털 API 이용하여 데이터 가져오기
# 지자체별 사고다발지역정보 조회 서비스
library(jsonlite)
library(openxlsx)
base_url <- "http://apis.data.go.kr/B552061/frequentzoneLg/getRestFrequentzoneLg"
ServiceKey <- 'lUXI2SxeMJiWbVfle8ayTUC1QdgcmsGBIFDe%2B81qXfYDKSUHzeXPgaJBDX3IN1NognSFegD5q6ggLws8MBwarQ%3D%3D'
searchYearCd <- 2017
siDo <- 30    # 대전광역시
guGun <- 170  # 서구
numOfRows <- 10
pageNo <- 1
# http://apis.data.go.kr/B552061/frequentzoneLg/getRestFrequentzoneLg?ServiceKey=서비스키&searchYearCd=2017&siDo=26&guGun=110&numOfRows=10&pageNo=1
callback_url <- paste0(base_url, '?ServiceKey=', ServiceKey, '&searchYearCd=', searchYearCd,
'&siDo=', siDo, '&guGun=', guGun, '&numOfRows=', numOfRows,
'&pageNo=', pageNo, '&type=json')
responsData <- fromJSON(callback_url)
responsData <- fromJSON(url(callback_url))
validate(callback_url)
responsData <- fromJSON(callback_url)
responsData <- fromJSON(validate(callback_url))
responsData <- fromJSON(callback_url)
responsData <- fromJSON(callback_url)
# 공공데이터포털 API 이용하여 데이터 가져오기
# 지자체별 사고다발지역정보 조회 서비스
library(jsonlite)
library(openxlsx)
base_url <- "http://apis.data.go.kr/B552061/frequentzoneLg/getRestFrequentzoneLg"
ServiceKey <- 'lUXI2SxeMJiWbVfle8ayTUC1QdgcmsGBIFDe%2B81qXfYDKSUHzeXPgaJBDX3IN1NognSFegD5q6ggLws8MBwarQ%3D%3D'
searchYearCd <- 2017
siDo <- 30    # 대전광역시
guGun <- 170  # 서구
numOfRows <- 10
pageNo <- 1
# http://apis.data.go.kr/B552061/frequentzoneLg/getRestFrequentzoneLg?ServiceKey=서비스키&searchYearCd=2017&siDo=26&guGun=110&numOfRows=10&pageNo=1
callback_url <- paste0(base_url, '?ServiceKey=', ServiceKey, '&searchYearCd=', searchYearCd,
'&siDo=', siDo, '&guGun=', guGun, '&numOfRows=', numOfRows,
'&pageNo=', pageNo, '&type=json')
responsData <- fromJSON(callback_url)
str(responsData)
cat("결과 코드 =", responsData$resultCode)
cat("결과 메시지 =", responsData$resultMsg)
cat("총 건수 =", responsData$totalCount)
str(responsData$items)
df_accidents <- responsData$items$item
str(df_accidents)
setwd('D:/Workspace/R_Project/03_JSON')
write.csv(df_accidents[-13], '사고다발지역.csv')
setwd('D:/Workspace/R/R_Project/03_JSON')
setwd('D:/workspace-Jwp/R/R-Project/02_JSON')
write.csv(df_accidents[-13], '사고다발지역.csv')
geoms <- df_accidents$geom_json
str(geoms)
library(openxlsx)
wb <- createWorkbook()
for (i in 1:length(geoms)) {
geom <- fromJSON(geoms[i])
str(geom)
# write.csv(geom$coordinates[1,,], paste0("olygon", i, ".csv"))
df_geom <- as.data.frame(geom$coordinates[1,,])
names(df_geom) <- c("경도", "위도")
addWorksheet(wb, paste0("polygon", i))
writeDataTable(wb, paste0("polygon", i), df_geom)
}
saveWorkbook(wb, file="polygon.xlsx")
saveWorkbook(wb, file="polygon.xlsx")
urlStr <- "https://openapi.naver.com/v1/search/blog.xml?" # 기본 url 생성
searchString <- "query=어린이집,맞벌이,육아휴직,경력단절" # 쿼리생성
searchString <- iconv(searchString, to="UTF-8") # 인코딩
searchString <- URLencode(searchString)
urlStr <- "https://openapi.naver.com/v1/search/blog.xml?" # 기본 url 생성
searchString <- "query=어린이집,맞벌이,육아휴직,경력단절" # 쿼리생성
searchString <- iconv(searchString, to="UTF-8") # 인코딩
searchString <- URLencode(searchString)
searchString
etcString <- "&display=100&start=1&sort=sim"
reqUrl <- paste(urlStr, searchString, etcString, sep="")
reqUrl # 요청할 url 생성
install.packages("httr")
library(httr)
clientid <- "054n6IEfBZCo9_YTAgR7" # 개인 api id 값
clientSecret <- "BejMyaYzl0" # 개인 apu secret 값
apiResult <- GET(reqUrl, add_headers("X-Naver-Client-Id"=clientid,
"X-Naver-Client-Secret"=clientSecret))
apiResult # Status 값이 200이어야 정상. 500 이면 시스템 에러
str(apiResult)
apiResult$content
result <- rawToChar(apiResult$content)
result
Encoding(result) <- "UTF-8"
result
library(rJava)
library(KoNLP)
library(wordcloud)
library(wordcloud2)
library(RColorBrewer)
useSejongDic()
library(dplyr)
library(stringr)
babymom <- sapply(result,extractNoun,USE.NAMES=F)
babymom <- gsub("<(\\/?)(\\w+)*([^<>]*)>", "", babymom)
babymom <- gsub("[[:punct:]]", "", babymom) # 문장부호 제거
babymom <- gsub("[[:cntrl:]]","",babymom) # 특수문자 제거
babymom <- gsub("[A-z]", "", babymom) # 모든 영문자 제거
babymom <- gsub("[0-9]", "", babymom) # 숫자 제거
babymom <- gsub(" +", "", babymom)
babymom <- gsub("^","", babymom)
babymom <- gsub("ㅋ","", babymom)
babymom <- gsub("ㅎ","", babymom)
babymom <- gsub("ㅜ","", babymom)
babymom <- gsub("naver","",babymom)
babymom <- gsub("blog","",babymom)
babymom <- gsub("https","",babymom)
babymom <- gsub("link","",babymom)
babymom <- gsub("title","",babymom)
babymom <- gsub("com","",babymom)
babymom <- Filter(function(x) {nchar(x)>=2 & nchar(x)<=4}, babymom)
babymom <- unlist(babymom)
wordcount <- table(babymom)
head(sort(wordcount,decreasing=T),100)
require(wordcloud2)
wordcloud2(wordcount,size=5,col="random-dark",rotateRatio=0.5,
backgroundColor="white",shape="circle")
library(tm)
## Association Analysis
# 출처1 : http://blog.naver.com/PostView.nhn?blogId=nonamed0000&logNo=220959156052&categoryNo=24&parentCategoryNo=0&viewDate=&currentPage=1&postListTopCurrentPage=1&from=postView
# 출처2 : http://blog.naver.com/PostView.nhn?blogId=nonamed0000&logNo=220965696087&parentCategoryNo=&categoryNo=24&viewDate=&isShowPopularPosts=false&from=postView
install.packages(tm)
## Association Analysis
# 출처1 : http://blog.naver.com/PostView.nhn?blogId=nonamed0000&logNo=220959156052&categoryNo=24&parentCategoryNo=0&viewDate=&currentPage=1&postListTopCurrentPage=1&from=postView
# 출처2 : http://blog.naver.com/PostView.nhn?blogId=nonamed0000&logNo=220965696087&parentCategoryNo=&categoryNo=24&viewDate=&isShowPopularPosts=false&from=postView
install.packages("tm")
library(tm)
library(arules)
install.packages("arules")
library(arules)
require(stringr)
ass.result <- result
ass.result <- str_split(ass.result, "</title>")
str(ass.result)
ass.babymom <- c()
for(i in 1:length(ass.result[[1]])) {
ass.babymom <- c(ass.babymom, ass.result[[1]][i])
}
head(ass.babymom,10)
ass.babymom <- gsub("<(\\/?)(\\w+)*([^<>]*)>","",ass.babymom)
ass.babymom <- gsub("[[:punct:]]","",ass.babymom) # 문장부호 제거
ass.babymom <- gsub("[[:cntrl:]]","",ass.babymom) # 특수문자 제거
ass.babymom <- gsub("[A-z]","",ass.babymom) # 모든 영문자 제거
ass.babymom <- gsub("[0-9]","",ass.babymom) # 숫자 제거
ass.babymom <- gsub("^","",ass.babymom)
ass.babymom <- gsub("ㅋ","",ass.babymom)
ass.babymom <- gsub("ㅎ","",ass.babymom)
ass.babymom <- gsub("ㅜ","",ass.babymom)
require(KoNLP)
lword <- Map(extractNoun,ass.babymom)
lword <- unique(lword) # 중복제거1(전체 대상)
lword <- sapply(lword, unique) # 중복제거2(줄 단위 대상)
lword[1:5] # 추출 단어 확인
# 1) 길이가 2~4 사이의 단어 필터링 함수 정의
filter1 <- function(x){
nchar(x) <= 4 && nchar(x) >= 2 && is.hangul(x)
}
# 2) Filter(f,x) -> filter1() 함수를 적용하여 x 벡터 단위 필터링
filter2 <- function(x){
Filter(filter1, x)
}
# 3) 줄 단어 대상 필터링
lword <- sapply(lword, filter2)
lword # 추출 단어 확인(길이 1개 단어 삭제됨)
wordtran <- as(lword, "transactions") # lword에 중복데이터가 있으면 error발생
wordtran
# 트랜잭션 내용 보기 -> 각 트랜잭션의 단어 보기
inspect(wordtran)
# 동일한 단어끼리 교차테이블 작성
wordtable <- crossTable(wordtran) # 교차표 작성
tranrules <- apriori(wordtran, parameter=list(supp=0.4, conf=0.05, minlen=2))
inspect(tranrules) # 연관규칙 생성 결과 보기
inspect(tranrules) # 연관규칙 생성 결과 보기
